{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification using Scikit-learn\n",
    "Find out at [this link](https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Workflow\n",
    "+ Understand the problem and identify potential features and label.\n",
    "+ Features are those characteristics or attributes which affect the results of the label.\n",
    "+ The classification has two phases:\n",
    "    + a learning phase\n",
    "    + the evaluation phase\n",
    "+ Performance is evaluated on the basis of various parameters:\n",
    "    + accuracy, error, precision, and recall.\n",
    "    \n",
    "![Classification workflow](images/nbc.webp \"Classification workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Naive Bayes Classifier?\n",
    "+ Naive Bayes classifier assumes that the effect of a particular feature in a class is independent of other features.\n",
    "+ Even if these features are interdependent, these features are still considered independently.\n",
    "+ This assumption simplifies computation, and that's why it is considered as naive.\n",
    "+ This assumption is called class conditional independence.\n",
    "\n",
    "![Bayes Theorem Equation for Naive Bayes Classification](images/nbc_equation.webp \"Bayes Theorem Equation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Naive Bayes classifier works?\n",
    "### First Approach (In case of a single feature)\n",
    "Naive Bayes classifier calculates the probability of an event in the following steps:\n",
    "\n",
    "+ **Step 1:** Calculate the prior probability for given class labels\n",
    "+ **Step 2:** Find Likelihood probability with each attribute for each class\n",
    "+ **Step 3:** Put these value in Bayes Formula and calculate posterior probability.\n",
    "+ **Step 4:** See which class has a higher probability, given the input belongs to the higher probability class.\n",
    "\n",
    "![Wheather Table](images/wheather-table-1.webp \"Wheather Table\")\n",
    "\n",
    "### Second Approach (In case of multiple features)\n",
    "\n",
    "![Wheather Table](images/wheather-table-2.webp \"Wheather Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Building in Scikit-learn\n",
    "### Naive Bayes Classifier\n",
    "#### Defining Dataset\n",
    "In this example, you can use the dummy dataset with three columns: weather, temperature, and play. The first two are features(weather, temperature) and the other is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features and label variables\n",
    "\n",
    "weather = ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast',\n",
    "           'Sunny','Sunny','Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "\n",
    "temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool',\n",
    "        'Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play = ['No','No','Yes','Yes','Yes','No','Yes',\n",
    "        'No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Features\n",
    "First, you need to convert these string labels into numbers. for example: 'Overcast', 'Rainy', 'Sunny' as 0, 1, 2. This is known as label encoding. Scikit-learn provides LabelEncoder library for encoding labels with a value between 0 and one less than the number of discrete classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#creating labelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded = le.fit_transform(weather)\n",
    "print(wheather_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can also encode temp and play columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting string labels into numbers\n",
    "\n",
    "temp_encoded = le.fit_transform(temp)\n",
    "label = le.fit_transform(play)\n",
    "\n",
    "print(f'Temp: {temp_encoded}')\n",
    "print(f'Play: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine both the features (weather and temp) in a single variable (list of tuples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "#Combinig weather and temp into single listof tuples\n",
    "\n",
    "features_zip = zip(weather_encoded,temp_encoded)\n",
    "features = list(features_zip)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Model\n",
    "Generate a model using naive bayes classifier in the following steps:\n",
    "+ Create naive bayes classifier\n",
    "+ Fit the dataset on classifier\n",
    "+ Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1]\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features, label)\n",
    "\n",
    "#Predict Output\n",
    "predicted = model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print(f'Predicted Value: {predicted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 1 indicates that players can 'play'.\n",
    "\n",
    "### Naive Bayes with Multiple Labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
